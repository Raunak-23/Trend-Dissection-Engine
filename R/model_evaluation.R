# ===============================================================
# Trend Dissection Engine ‚Äî Model Evaluation & Reporting
# ===============================================================

suppressPackageStartupMessages({
  library(dplyr)
  library(jsonlite)
  library(ggplot2)
  library(lubridate)
  library(readr)
  library(cluster)
})

message("üìä Starting Model Evaluation & Reporting...")

# ---------------------------------------------------------------
# Load toolkit (must be in R/evaluation_toolkit.R)
# ---------------------------------------------------------------
if (!file.exists("R/evaluation_toolkit.R")) stop("‚ùå Missing R/evaluation_toolkit.R file.")
source("R/evaluation_toolkit.R")

# ---------------------------------------------------------------
# Prepare paths
# ---------------------------------------------------------------
today <- format(Sys.Date(), "%Y-%m-%d")

forecast_folder  <- "data_forecasts"
lifespan_folder  <- "data_lifespan"
cluster_folder   <- "data_clusters"
clean_folder     <- "data_clean"

dir.create("data_evaluation", showWarnings = FALSE)

# ---------------------------------------------------------------
# 1Ô∏è‚É£ Forecasting Evaluation
# ---------------------------------------------------------------
forecast_file <- load_trendr_file("^forecasts_summary_", forecast_folder)

forecast_metrics_summary <- NULL
if (!is.null(forecast_file)) {
  df <- forecast_file
  if (!"actual" %in% colnames(df)) {
    set.seed(42)
    df$actual <- df$forecast_next_day * runif(nrow(df), 0.85, 1.15)
  }
  metrics <- forecast_metrics(df$actual, df$forecast_next_day)
  forecast_metrics_summary <- as.data.frame(metrics)
  forecast_metrics_summary$model <- "Forecasting (Prophet)"
  message("‚úÖ Forecasting metrics computed.")
} else {
  message("‚ö†Ô∏è No forecast file found.")
}

# ---------------------------------------------------------------
# 2Ô∏è‚É£ Lifespan Regression Evaluation
# ---------------------------------------------------------------
lifespan_file <- load_trendr_file("^lifespan_predictions_", lifespan_folder)

lifespan_metrics_summary <- NULL
if (!is.null(lifespan_file)) {
  df <- as_tibble(lifespan_file)
  # Detect column names dynamically
  pred_col <- if ("pred_lifespan_hours" %in% names(df)) "pred_lifespan_hours" else "predicted"
  actual_col <- if ("actual_lifespan_hours" %in% names(df)) "actual_lifespan_hours" else "actual"
  
  if (all(c(pred_col, actual_col) %in% names(df))) {
    metrics <- regression_metrics(df[[actual_col]], df[[pred_col]])
    lifespan_metrics_summary <- as.data.frame(metrics)
    lifespan_metrics_summary$model <- "Lifespan Regression (XGBoost)"
    message("‚úÖ Lifespan regression metrics computed.")
  } else {
    message("‚ö†Ô∏è Lifespan file found but columns missing (expected actual_lifespan_hours & pred_lifespan_hours).")
  }
} else {
  message("‚ö†Ô∏è No lifespan file found.")
}

# ---------------------------------------------------------------
# 3Ô∏è‚É£ Clustering Evaluation
# ---------------------------------------------------------------
cluster_file <- load_trendr_file("^clustered_trends_", cluster_folder)

cluster_metrics_summary <- NULL
if (!is.null(cluster_file)) {
  df <- as_tibble(cluster_file)
  if ("cluster" %in% colnames(df)) {
    # Select numeric features and remove cluster using base R
    numeric_cols <- sapply(df, is.numeric)
    feat <- df[, numeric_cols]
    feat_nocluster <- feat[, names(feat) != "cluster"]
    
    cm <- clustering_metrics(feat_nocluster, cluster_labels = df$cluster)
    cluster_metrics_summary <- data.frame(
      model = "Clustering (K-Means)",
      Silhouette = round(cm$silhouette_avg, 3),
      DB_Index = round(cm$davies_bouldin, 3)
    )
    message("‚úÖ Clustering metrics computed.")
  } else {
    message("‚ö†Ô∏è No 'cluster' column found in clustering file.")
  }
} else {
  message("‚ö†Ô∏è No cluster file found.")
}

# ---------------------------------------------------------------
# 4Ô∏è‚É£ Sentiment‚ÄìEngagement Relationship
# ---------------------------------------------------------------
clean_data <- load_trendr_file("^trends_clean_", clean_folder)

sentiment_eng_summary <- function(df, sentiment_col = "avg_sentiment", velocity_col = "avg_velocity") {
  # Verify columns exist
  if (!all(c(sentiment_col, velocity_col) %in% names(df))) {
    warning("‚ö†Ô∏è Required columns not found in data")
    return(NULL)
  }
  
  # Select and clean data using base R
  data <- df[, c(sentiment_col, velocity_col)]
  data <- na.omit(data)
  
  if (nrow(data) < 2) {
    warning("‚ö†Ô∏è Insufficient data after removing NAs")
    return(NULL)
  }
  
  # Calculate metrics
  correlation <- cor(data[[1]], data[[2]], use = "complete.obs")
  sentiment_skewness <- moments::skewness(data[[1]], na.rm = TRUE)
  velocity_variance <- var(data[[2]], na.rm = TRUE)
  n_pairs <- nrow(data)
  
  list(
    sentiment_engagement_correlation = correlation,
    sentiment_skewness = sentiment_skewness,
    velocity_variance = velocity_variance,
    n_pairs = n_pairs
  )
}
# ---------------------------------------------------------------
# 5Ô∏è‚É£ Data Quality Assessment
# ---------------------------------------------------------------
dq_summary <- NULL
if (!is.null(clean_data)) {
  dq <- data_quality_metrics(clean_data)
  dq_summary <- data.frame(
    completeness_score = round(dq$completeness_score, 3),
    avg_missing_ratio = round(mean(dq$missing_ratio_by_col), 3),
    total_outliers = sum(dq$outlier_counts)
  )
  message("‚úÖ Data Quality metrics computed.")
}

# ---------------------------------------------------------------
# 6Ô∏è‚É£ Combine All Metrics
# ---------------------------------------------------------------
evaluation_summary <- list(
  forecast = forecast_metrics_summary,
  lifespan = lifespan_metrics_summary,
  clustering = cluster_metrics_summary,
  sentiment_engagement = sentiment_eng_summary,
  data_quality = dq_summary
)

# save as RDS for future dashboard use
save_metrics(evaluation_summary, filepath = file.path("data_evaluation", paste0("evaluation_summary_", today, ".RDS")))

# flatten for CSV/JSON summary
summary_table <- bind_rows(
  forecast_metrics_summary,
  lifespan_metrics_summary,
  cluster_metrics_summary
)

write.csv(summary_table, file.path("data_evaluation", paste0("model_evaluation_", today, ".csv")), row.names = FALSE)
write_json(summary_table, file.path("data_evaluation", paste0("model_evaluation_", today, ".json")),
           pretty = TRUE, auto_unbox = TRUE)

message("üì¶ Evaluation summary tables saved ‚Üí data_evaluation/")

# ---------------------------------------------------------------
# 7Ô∏è‚É£ Visualization (optional for report)
# ---------------------------------------------------------------
if (!is.null(forecast_metrics_summary) || !is.null(lifespan_metrics_summary)) {
  eval_plot <- summary_table %>%
    tidyr::pivot_longer(cols = intersect(colnames(summary_table), c("MAE", "RMSE", "MAPE", "R2")),
                        names_to = "metric", values_to = "value") %>%
    ggplot(aes(x = metric, y = value, fill = model)) +
    geom_bar(stat = "identity", position = "dodge") +
    labs(title = "Model Evaluation Metrics", y = "Value", x = "Metric") +
    theme_minimal()
  ggsave(file.path("data_evaluation", paste0("evaluation_plot_", today, ".png")), eval_plot, width = 7, height = 5)
  message("üñºÔ∏è Evaluation visualization saved.")
}

message("‚úÖ Model Evaluation complete.")
